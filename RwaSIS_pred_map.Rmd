---
title: RwaSIS predictive soil mapping workflows 
author: M.G. Walsh, B.A. Walsh, R. Manners and J. Chamberlin
date: "`r format(Sys.time(), '%d, %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 1
    css: style.css
---

# Introduction

The first section of this notebook sets up georeferenced soil and remote sensing data of Rwanda for spatial analyses and predictions. We focus on *Croplands*, which are the primary [Region of Interest (ROI)](https://en.wikipedia.org/wiki/Region_of_interest) and the target for various land management interventions of the [RwaSIS project](https://minagri.prod.risa.rw/updates/news-details/rwanda-launches-soil-information-service-project-to-improve-agriculture-productivity). Based on a recent high-resolution remote-sensing [GeoSurvey (2019)](https://osf.io/w5e6c/), croplands are currently estimated to occupy ~68% of Rwanda's overall land area (of ~2.37 Mha). 

The subsequent sections illustrate prediction and mapping workflows, which use ensembles of machine learning algorithms (MLAs), (see e.g. the various review articles at: [Emsemble models](https://www.sciencedirect.com/topics/computer-science/ensemble-modeling)) with various remote sensing and GIS input layers. While the [Legacy soil data](https://en.wikipedia.org/wiki/Legacy_system) used in this example were not collected on a replicable geostatistical sampling frame, they do provide an inital indication of where specific soil problems or nutrient deficiencies/imbalances may be prevalent in Rwanda; thus, warranting potentially differentiated research and soil testing approaches. As new RwaSIS project soil and landscape data become available over the course of the project, we will update the relevant data sources and soil mapping workflows.

In the last section of the notebook, we produce uncertainty estimates of the soil property predictions that are generated by our ensemble model workflow via [Quantile Regression](https://cran.r-project.org/web/packages/quantreg/quantreg.pdf). These estimates show where in Rwanda the current models fit the ground measurements reasonably well and where they do not. As new data are generated by RwaSIS (and others) these uncertainties are likely to decrease, potentially increasing the level of confidence in the resulting cropland management recommendations (e.g. for fertilizer, lime requirement and soil erosion predictions). 

# General data setup

For each predictive soil map, you'll intially need a (current) data setup. If you are using [R](https://www.r-project.org/), you will need to use the packages indicated in the chunk directly below. This allows you to assemble the different dataframes and rasters providing a lot of options to generate spatial predictions via machine learning and/or geostatistical algorithms. We encourage and challenge you to explore the options!

```{r}
# Required packages
suppressPackageStartupMessages({
  require(downloader)
  require(rgdal)
  require(raster)
  require(DT)
  require(leaflet)
  require(htmlwidgets)
})
```

The following chunk then downloads the data needed for running this particular example. Specifically, it assembles georeferenced field observations of soil measurements, e.g. (pH, soil carbon and soil nutrient composition) and links these to remote sensing and GIS images represented by `grids`. We initially focus on predicting the topsoil pH measurements here, but the approach is applicable to any given  [Georeferenced](https://en.wikipedia.org/wiki/Georeferencing) soil property or measurement under consideration. 

```{r}
# Data downloads -----------------------------------------------------------
# Create a data folder in  your current working directory
dir.create("Wetchem", showWarnings=F)
setwd("./Wetchem")

# download soil data
download("https://osf.io/djcfz?raw=1", "RW_wetchem.zip", mode = "wb")
unzip("RW_wetchem.zip", overwrite = T)
prof <- read.table("Profiles.csv", header = T, sep = ",")
samp <- read.table("Samples.csv", header = T, sep = ",")
geos <- merge(prof, samp, by="pid")

# download and assemble raster stacks
download("https://osf.io/hp6v7?raw=1", "RW_250m_2020.zip", mode = "wb")
unzip("RW_250m_2020.zip", overwrite = T)
download("https://osf.io/u73pd?raw=1", "RW_GS_preds.zip", mode = "wb")
unzip("RW_GS_preds.zip", overwrite = T)
glist <- list.files(pattern="tif", full.names = T)
grids <- stack(glist)
```

The processed Rwanda remote sensing and GIS data (covariates, ... `grids` in the chunk above) were derived from and reused from their primary open sources. You can download those at [RwaSIS grids](https://osf.io/hp6v7/). The short descriptions of the covariates included in the `grids` raster stack and their sources are provided in the table immediately below:

\
```{r, echo=FALSE}

```
\
These covariates may change over time and we will update them when and where needed. The following chunk then sets up the legacy soil property data in a dataframe that will subsequently generate the the training and validation dataframes for the different MLAs we shall apply to the spatial prediction of soil properties. The soil property data presented here are courtesy of [CROPNUTS](https://cropnuts.com/). 

```{r}
# Data setup --------------------------------------------------------------
# project legacy data coords to grid CRS
geos.proj <- as.data.frame(project(cbind(geos$lon, geos$lat), "+proj=laea +ellps=WGS84 +lon_0=20 +lat_0=5 +units=m +no_defs"))
colnames(geos.proj) <- c("x","y")
geos <- cbind(geos, geos.proj)
coordinates(geos) <- ~x+y
projection(geos) <- projection(grids)

# extract gridded variables at survey locations
geosgrid <- extract(grids, geos)
gsdat <- as.data.frame(cbind(geos, geosgrid))
```

This chunk writes out the dataframe `RW_soil_data.csv` into your `./Results` directory if you'd like to process those outputs in software other than R.

```{r}
# Write data frame --------------------------------------------------------
dir.create("Results", showWarnings = F)
write.csv(gsdat, "./Results/RW_soil_data.csv", row.names = F)

# Soil sample locations ---------------------------------------------------
w <- leaflet() %>%
  setView(lng = mean(gsdat$lon), lat = mean(gsdat$lat), zoom = 8) %>%
  addProviderTiles(providers$OpenStreetMap.Mapnik) %>%
  addCircleMarkers(gsdat$lon, gsdat$lat, clusterOptions = markerClusterOptions())
saveWidget(w, 'RW_soil_sample_locs.html', selfcontained = T) ## save widget
w ## plot widget 
```

# Machine-learning-based predictive mapping

The following chunks predict topsoil soil pH values using different machine learning models with varying remote sensing and GIS (covariate) inputs. The general MLA prediction workflow is shown in the figure below: ...

The main idea is to initially run a number of potentially contrasting models with [k-fold cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)). At the end of the model fitting processes, the various models are ensembled (combined/stacked) on an *independent* validation dataset. When applied over time and space, this is a form of [Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning), which should produce increasingly accurate predictions as new field, lab data and MLAs are obtained. 

To run this section of the notebook, you may need to install and load some of the additional R-packages needed to run the example. You can always alter these and/or automatically adjust and/or add other MLAs using `caret` package see at: [caret](https://topepo.github.io/caret/index.html), as you see fit.

```{r}
# Required packages
# install.packages(c("devtools","caret","mgcv","MASS","randomForest","gbm","Cubist","plyr","doParallel","dismo")), dependencies=T)
suppressPackageStartupMessages({
  require(devtools)
  require(caret)
  require(mgcv)
  require(MASS)
  require(randomForest)
  require(gbm)
  require(Cubist)
  require(plyr)
  require(doParallel)
})
```

The following chunk scrubs some of the objects in memory, removes incomplete cases (if there are any), sets-up labels and features, and creates a randomized partion between the training and validation dataframes. Everything is parallelized to facilitate efficient use of either local or cloud-based computing resources. Note that there are other options available for this (e.g. [foreach](https://cran.r-project.org/web/packages/foreach/vignettes/foreach.html), among others).

```{r}
# Data setup --------------------------------------------------------------
rm(list=setdiff(ls(), c("gsdat","grids","glist"))) ## scrub extraneous objects in memory
gsdat <- gsdat[complete.cases(gsdat[ ,c(24:77)]),] ## removes incomplete cases

# set calibration/validation set randomization seed
seed <- 12358
set.seed(seed)

# split data into calibration and validation sets
gsIndex <- createDataPartition(gsdat$pH, p = 4/5, list = F, times = 1)
gs_cal <- gsdat[ gsIndex,]
gs_val <- gsdat[-gsIndex,]

# Soil calibration labels
labs <- c("pH") ## insert other labels (e.g. "C","N","P","K" ...) here!
lcal <- as.vector(t(gs_cal[labs]))

# raster calibration features
fcal <- gs_cal[,24:48,52:79]
```

Note that we are using topsoil (0-20 cm) pH as an example in ths context. You can substitute other soil properties like (C, N, P, K, etc.) as labels, in the `labs` variable that is to be predicted. You may want to transform those `labs` variables prior to model fitting, and perhaps also to tune the respsective models to better represent the distributional and/or compositional attributes of the indiviual soil properties.

## Spatial trend model ([mgcv](https://cran.r-project.org/web/packages/mgcv/mgcv.pdf))

This a simple spatially smoothed *generalized additive model* applying the `gam` function on the pH values at different sampling locations in Rwanda, based only on their georeference. It is similar to ordinary kriging with cross-validation ... but it is simpler and much faster to compute in this context.

```{r, results='hide'}
# select locational covariates
gf_cpv <- gs_cal[,49:51]

# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

# model training
gm <- train(gf_cpv, lcal, 
            method = "gam",
            preProc = c("center","scale"), 
            metric = "RMSE",
            trControl = tc)

# model outputs & predictions
gm.pred <- predict(grids, gm) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_gm.rds", sep = "")
saveRDS(gm, fname)
```

## Central place model ([MASS](https://cran.r-project.org/web/packages/MASS/MASS.pdf))

Central places are influential variables in places where human impacts occur. They are correlated with both extraction and deposition of soil nutrients and toxic elements, soil erosion and deposition, acidification and many other soil disturbance processess. The model below focuses on central place indicators such as distances to roads and settlements, surface water sources, cell towers and electricity networks among others.

```{r, results = 'hide'}
# select central place covariates
gf_cpv <- gs_cal[,35:48,67]

# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

# model training
gl1 <- train(gf_cpv, lcal, 
             method = "glmStepAIC",
             preProc = c("center","scale"), 
             trControl = tc,
             metric = "RMSE")

# model outputs & predictions
gl1.pred <- predict(grids, gl1) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_gl1.rds", sep = "")
saveRDS(gl1, fname)
```

## GLM with all spatial covariates ([MASS](https://cran.r-project.org/web/packages/MASS/MASS.pdf))

```{r, results='hide'}
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

# model training
gl2 <- train(fcal, lcal, 
             method = "glmStepAIC",
             preProc = c("center","scale"), 
             trControl = tc,
             metric ="RMSE")

# model outputs & predictions
gl2.pred <- predict(grids, gl2) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_gl2.rds", sep = "")
saveRDS(gl2, fname)
```

## Random forest ([randomForest](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf))

The below is a ...

```{r, results='hide'}
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)
tg <- expand.grid(mtry = seq(5,10, by=1)) ## model tuning steps

# model training
rf <- train(fcal, lcal,
            preProc = c("center","scale"),
            method = "rf",
            ntree = 501,
            metric = "RMSE",
            tuneGrid = tg,
            trControl = tc)

# model outputs & predictions
print(rf) ## RMSE's accross tuning parameters
rf.pred <- predict(grids, rf) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_rf.rds", sep = "")
saveRDS(rf, fname)
```

## Generalized boosting ([gbm](https://cran.r-project.org/web/packages/gbm/gbm.pdf))

This next chunk represents one of bagging techniques that are coommonly used for ...

```{r, results='hide'}
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

## for initial <gbm> tuning guidelines see @ https://stats.stackexchange.com/questions/25748/what-are-some-useful-guidelines-for-gbm-parameters
tg <- expand.grid(interaction.depth = seq(2,5, by=1), shrinkage = 0.01, n.trees = seq(101,501, by=50),
                  n.minobsinnode = 50) ## model tuning steps

# model training
gb <- train(fcal, lcal, 
            method = "gbm", 
            preProc = c("center", "scale"),
            trControl = tc,
            tuneGrid = tg,
            metric = "RMSE")

# model outputs & predictions
print(gb) ## RMSE's accross tuning parameters
gb.pred <- predict(grids, gb) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_gb.rds", sep = "")
saveRDS(gb, fname)
```

## Cubist ([Cubist](https://cran.r-project.org/web/packages/Cubist/Cubist.pdf))

```{r, results='hide'}
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(seed)
tc <- trainControl(method="repeatedcv", number=10, repeats=3, allowParallel = T)
# tg <- needs tuning

cu <- train(fcal, lcal, 
            method = "cubist", 
            trControl = tc,
            metric = "RMSE")

print(cu)
cu.pred <- predict(grids, cu) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_cu.rds", sep = "")
saveRDS(cu, fname)
```

# Model stacking

```{r}
# Stacking setup ------------------------------------------------------------
preds <- stack(gm.pred, gl1.pred, gl2.pred, rf.pred, gb.pred, cu.pred)
names(preds) <- c("gm","gl1","gl2","rf","gb","cu")
# plot(preds, axes = F)

# extract model predictions
coordinates(gs_val) <- ~x+y
projection(gs_val) <- projection(preds)
gspred <- extract(preds, gs_val)
gspred <- as.data.frame(cbind(gs_val, gspred))

# stacking model validation labels and features
gs_val <- as.data.frame(gs_val)
lval <- as.vector(t(gs_val[labs]))
fval <- gspred[,80:85] ## subset validation features
```

This chunk does the model stacking with `glmStepAIC` function from the `MASS` library. You could explore other options here, but we find that this gives reasonably ...

```{r}
# Stacked model -------------------------------------------------------------
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# model setup
set.seed(seed)
tc <- trainControl(method="repeatedcv", number=10, repeats=3, allowParallel=T)

st <- train(fval, lval,
            method = "glmStepAIC",
            trControl = tc,
            metric = "RMSE")

summary(st)
st.pred <- predict(preds, st) ## spatial predictions
stopCluster(mc)
plot(st.pred, axes=F)
fname <- paste("./Results/", labs, "_st.rds", sep = "")
saveRDS(st, fname)
```



```{r}
# Write prediction grids --------------------------------------------------
gspreds <- stack(preds, st.pred)
names(gspreds) <- c("gm","gl1","gl2","rf","gb","cu","st")
fname <- paste("./Results/","RW_", labs, "_preds_2020.tif", sep = "")
writeRaster(gspreds, filename=fname, datatype="FLT4S", options="INTERLEAVE=BAND", overwrite=T)
```

# Prediction uncertainty estimates

```{r}
# Uncertainty estimates via quantile regression ---------------------------
# note that this is just an example for pH ... generalize & move to a seperate script
require(quantreg)

coordinates(gsdat) <- ~x+y
projection(gsdat) <- projection(grids)
gspre <- extract(gspreds, gsdat)
gsout <- as.data.frame(cbind(gsdat, gspre))

# estimate & plot
par(pty="s")
par(mfrow=c(1,1), mar=c(5,5,1,1))
plot(pH~st, xlab="Ensemble prediction", ylab="pH (water)", cex.lab=1.3, 
     xlim=c(3,9), ylim=c(3,9), gsout)
stQ <- rq(pH~st, tau=c(0.05,0.5,0.95), data=gsout)
print(stQ)
curve(stQ$coefficients[2]*x+stQ$coefficients[1], add=T, from=3, to=9, col="blue", lwd=2)
curve(stQ$coefficients[4]*x+stQ$coefficients[3], add=T, from=3, to=9, col="red", lwd=2)
curve(stQ$coefficients[6]*x+stQ$coefficients[5], add=T, from=3, to=9, col="blue", lwd=2)
```



```{r}
# Spatial residual --------------------------------------------------------
# note that this is just an example for pH ... generalize & move to a seperate script

# calculate spatial residual
gsout$lres <- gsout$pH - gsout$st

# select locational covariates
gf_loc <- gsout[,47:49]

# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

# model training
sres <- train(gf_loc, gsout$lres, 
              method = "gam",
              preProc = c("center","scale"), 
              metric = "RMSE",
              trControl = tc)

# model outputs & predictions
summary(sres)
sres.pred <- predict(grids, sres) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_sres.rds", sep = "")
saveRDS(sres, fname)
```

