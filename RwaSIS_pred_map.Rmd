---
title: RwaSIS predictive soil mapping 
author: M.G. Walsh and R. Manners
date: "`r format(Sys.time(), '%d, %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 1
    css: style.css
---

# Introduction

The first section of this notebook sets up georeferenced soil and remote sensing data of Rwanda for spatial analyses and predictions. We focus on *Croplands*, which are the primary [Region of Interest (ROI)](https://en.wikipedia.org/wiki/Region_of_interest) and the target for various land management interventions of the [RwaSIS project](https://minagri.prod.risa.rw/updates/news-details/rwanda-launches-soil-information-service-project-to-improve-agriculture-productivity). Based on a recent high-resolution remote-sensing [GeoSurvey (2019)](https://osf.io/w5e6c/), croplands are currently estimated to occupy ~68% of Rwanda's overall land area (of ~2.37 Mha). 

The subsequent sections demonstrate relatively generic prediction and mapping workflows, which use ensembles of different and complimentary machine learning (ML) algorithms (see e.g. the various review articles at: [Emsemble models](https://www.sciencedirect.com/topics/computer-science/ensemble-modeling)) using the various remote sensing and GIS layers. While the *"legacy data"* used in this example were not collected on a replicable geostatistical sampling frame, they provide an inital indication of where specific soil problems or nutrient deficiencies may be prevalent in Rwanda; thus, warranting potentially different research approaches. As new RwaSIS project data become available over the course of the project, we will update the relevant data sources and soil mapping workflows.

Finally, we produce uncertainty estimates of the soil property predictions that are generated. These are intended to indicate where in Rwanda the current models fit the measurements well and where they do not.  

# General data setup

For each predictive soil map, you'll intially need a data setup. If you are using [R](https://www.r-project.org/), you will need to use the packages indicated in the chunk directly below. This allows you to assemble the different dataframes and rasters allowing you to generate spatial predictions via machine learning and/or other algorithms.

```{r}
# Required packages
suppressPackageStartupMessages({
  require(downloader)
  require(rgdal)
  require(raster)
  require(DT)
  require(leaflet)
  require(htmlwidgets)
})
```

The following chunk then downloads the needed data for running this example. Specifically, it assembles georeferenced point observations of soil measurements, e.g. (pH, soil carbon and soil nutrient composition) and links these to remote sensing and GIS images `grids` . 

```{r}
# Data downloads -----------------------------------------------------------
# Create a data folder in  your current working directory
dir.create("Wetchem", showWarnings=F)
setwd("./Wetchem")

# download soil data
download("https://osf.io/djcfz?raw=1", "RW_wetchem.zip", mode = "wb")
unzip("RW_wetchem.zip", overwrite = T)
prof <- read.table("Profiles.csv", header = T, sep = ",")
samp <- read.table("Samples.csv", header = T, sep = ",")
geos <- merge(prof, samp, by="pid")

# download and assemble raster stacks
download("https://osf.io/hp6v7?raw=1", "RW_250m_2020.zip", mode = "wb")
unzip("RW_250m_2020.zip", overwrite = T)
download("https://osf.io/u73pd?raw=1", "RW_GS_preds.zip", mode = "wb")
unzip("RW_GS_preds.zip", overwrite = T)
glist <- list.files(pattern="tif", full.names = T)
grids <- stack(glist)
```



```{r}
# Data setup --------------------------------------------------------------
# project GeoSurvey coords to grid CRS
geos.proj <- as.data.frame(project(cbind(geos$lon, geos$lat), "+proj=laea +ellps=WGS84 +lon_0=20 +lat_0=5 +units=m +no_defs"))
colnames(geos.proj) <- c("x","y")
geos <- cbind(geos, geos.proj)
coordinates(geos) <- ~x+y
projection(geos) <- projection(grids)

# extract gridded variables at survey locations
geosgrid <- extract(grids, geos)
gsdat <- as.data.frame(cbind(geos, geosgrid))
```



```{r}
# Write data frame --------------------------------------------------------
dir.create("Results", showWarnings = F)
write.csv(gsdat, "./Results/RW_soil_data.csv", row.names = F)

# Soil sample locations ---------------------------------------------------
w <- leaflet() %>%
  setView(lng = mean(gsdat$lon), lat = mean(gsdat$lat), zoom = 9) %>%
  addProviderTiles(providers$OpenStreetMap.Mapnik) %>%
  addCircleMarkers(gsdat$lon, gsdat$lat, clusterOptions = markerClusterOptions())
saveWidget(w, 'RW_soil_sample_locs.html', selfcontained = T) ## save widget
w ## plot widget 
```

# Machine-learning-based mapping models



```{r}
# Required packages
# install.packages(c("devtools","caret","mgcv","MASS","randomForest","gbm","Cubist","plyr","doParallel","dismo")), dependencies=T)
suppressPackageStartupMessages({
  require(devtools)
  require(caret)
  require(mgcv)
  require(MASS)
  require(randomForest)
  require(gbm)
  require(Cubist)
  require(plyr)
  require(doParallel)
})
```



```{r}
# Data setup --------------------------------------------------------------
rm(list=setdiff(ls(), c("gsdat","grids","glist"))) ## scrub extraneous objects in memory
gsdat <- gsdat[complete.cases(gsdat[ ,c(24:77)]),] ## removes incomplete cases

# set calibration/validation set randomization seed
seed <- 12358
set.seed(seed)

# split data into calibration and validation sets
gsIndex <- createDataPartition(gsdat$pH, p = 4/5, list = F, times = 1)
gs_cal <- gsdat[ gsIndex,]
gs_val <- gsdat[-gsIndex,]

# Soil calibration labels
labs <- c("pH") ## insert other labels (e.g. "C","N","P","K" ...) here!
lcal <- as.vector(t(gs_cal[labs]))

# raster calibration features
fcal <- gs_cal[,24:46,50:77]
```

## Spatial trend model [mgcv](https://cran.r-project.org/web/packages/mgcv/mgcv.pdf)

```{r}
# select locational covariates
gf_cpv <- gs_cal[,47:49]

# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

# model training
gm <- train(gf_cpv, lcal, 
            method = "gam",
            preProc = c("center","scale"), 
            metric = "RMSE",
            trControl = tc)

# model outputs & predictions
summary(gm)
gm.pred <- predict(grids, gm) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_gm.rds", sep = "")
saveRDS(gm, fname)
```

# Central place theory model <glm>

```{r}
# select central place covariates
gf_cpv <- gs_cal[,33:46]

# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", classProbs = T, allowParallel = T)

# model training
gl1 <- train(gf_cpv, lcal, 
             method = "glmStepAIC",
             preProc = c("center","scale"), 
             trControl = tc,
             metric = "RMSE")

# model outputs & predictions
summary(gl1)
print(gl1) ## ROC's accross cross-validation
gl1.pred <- predict(grids, gl1) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_gl1.rds", sep = "")
saveRDS(gl1, fname)
```

## GLM with all covariates

```{r}
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

# model training
gl2 <- train(fcal, lcal, 
             method = "glmStepAIC",
             preProc = c("center","scale"), 
             trControl = tc,
             metric ="RMSE")

# model outputs & predictions
summary(gl2)
print(gl2)
gl2.pred <- predict(grids, gl2) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_gl2.rds", sep = "")
saveRDS(gl2, fname)
```

## Random forest <randomForest>

```{r}
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)
tg <- expand.grid(mtry = seq(5,10, by=1)) ## model tuning steps

# model training
rf <- train(fcal, lcal,
            preProc = c("center","scale"),
            method = "rf",
            ntree = 501,
            metric = "RMSE",
            tuneGrid = tg,
            trControl = tc)

# model outputs & predictions
print(rf) ## RMSE's accross tuning parameters
rf.pred <- predict(grids, rf) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_rf.rds", sep = "")
saveRDS(rf, fname)
```

## Generalized boosting <gbm>

```{r}
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

## for initial <gbm> tuning guidelines see @ https://stats.stackexchange.com/questions/25748/what-are-some-useful-guidelines-for-gbm-parameters
tg <- expand.grid(interaction.depth = seq(2,5, by=1), shrinkage = 0.01, n.trees = seq(101,501, by=50),
                  n.minobsinnode = 50) ## model tuning steps

# model training
gb <- train(fcal, lcal, 
            method = "gbm", 
            preProc = c("center", "scale"),
            trControl = tc,
            tuneGrid = tg,
            metric = "RMSE")

# model outputs & predictions
print(gb) ## RMSE's accross tuning parameters
gb.pred <- predict(grids, gb) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_gb.rds", sep = "")
saveRDS(gb, fname)
```

## Cubist <Cubist>

```{r}
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(seed)
tc <- trainControl(method="repeatedcv", number=10, repeats=3, allowParallel = T)
# tg <- needs tuning

cu <- train(fcal, lcal, 
            method = "cubist", 
            trControl = tc,
            metric = "RMSE")

print(cu)
cu.pred <- predict(grids, cu) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_cu.rds", sep = "")
saveRDS(cu, fname)
```

# Model stacking

```{r}
# Stacking setup ------------------------------------------------------------
preds <- stack(gm.pred, gl1.pred, gl2.pred, rf.pred, gb.pred, cu.pred)
names(preds) <- c("gm","gl1","gl2","rf","gb","cu")
plot(preds, axes = F)

# extract model predictions
coordinates(gs_val) <- ~x+y
projection(gs_val) <- projection(preds)
gspred <- extract(preds, gs_val)
gspred <- as.data.frame(cbind(gs_val, gspred))

# stacking model validation labels and features
gs_val <- as.data.frame(gs_val)
lval <- as.vector(t(gs_val[labs]))
fval <- gspred[,78:83] ## subset validation features
```


```{r}
# Stacked model -------------------------------------------------------------
# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# model setup
set.seed(seed)
tc <- trainControl(method="repeatedcv", number=10, repeats=3, allowParallel=T)

st <- train(fval, lval,
            method = "glmStepAIC",
            trControl = tc,
            metric = "RMSE")

print(st)
summary(st)
st.pred <- predict(preds, st) ## spatial predictions
stopCluster(mc)
plot(st.pred, axes=F)
fname <- paste("./Results/", labs, "_st.rds", sep = "")
saveRDS(st, fname)
```



```{r}
# Write prediction grids --------------------------------------------------
gspreds <- stack(preds, st.pred)
names(gspreds) <- c("gm","gl1","gl2","rf","gb","cu","st")
fname <- paste("./Results/","RW_", labs, "_preds_2020.tif", sep = "")
writeRaster(gspreds, filename=fname, datatype="FLT4S", options="INTERLEAVE=BAND", overwrite=T)
```

# Prediction uncertainty estimates

```{r}
# Uncertainty estimates via quantile regression ---------------------------
# note that this is just an example for pH ... generalize & move to a seperate script
require(quantreg)

coordinates(gsdat) <- ~x+y
projection(gsdat) <- projection(grids)
gspre <- extract(gspreds, gsdat)
gsout <- as.data.frame(cbind(gsdat, gspre))

# estimate & plot
par(pty="s")
par(mfrow=c(1,1), mar=c(5,5,1,1))
plot(pH~st, xlab="Ensemble prediction", ylab="pH (water)", cex.lab=1.3, 
     xlim=c(3,9), ylim=c(3,9), gsout)
stQ <- rq(pH~st, tau=c(0.05,0.5,0.95), data=gsout)
print(stQ)
curve(stQ$coefficients[2]*x+stQ$coefficients[1], add=T, from=3, to=9, col="blue", lwd=2)
curve(stQ$coefficients[4]*x+stQ$coefficients[3], add=T, from=3, to=9, col="red", lwd=2)
curve(stQ$coefficients[6]*x+stQ$coefficients[5], add=T, from=3, to=9, col="blue", lwd=2)
```



```{r}
# Spatial residual --------------------------------------------------------
# note that this is just an example for pH ... generalize & move to a seperate script

# calculate spatial residual
gsout$lres <- gsout$pH - gsout$st

# select locational covariates
gf_loc <- gsout[,47:49]

# start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# control setup
set.seed(1385321)
tc <- trainControl(method = "cv", allowParallel = T)

# model training
sres <- train(gf_loc, gsout$lres, 
              method = "gam",
              preProc = c("center","scale"), 
              metric = "RMSE",
              trControl = tc)

# model outputs & predictions
summary(sres)
sres.pred <- predict(grids, sres) ## spatial predictions
stopCluster(mc)
fname <- paste("./Results/", labs, "_sres.rds", sep = "")
saveRDS(sres, fname)
```

