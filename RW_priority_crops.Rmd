---
title: Crop distribution predictions from survey data and small area estimates
author: M.G. Walsh, J. Rutebuka and R. Manners
date: "`r format(Sys.time(), '%d, %B, %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 1
    fig_caption: true
    css: style.css
---

```{r, echo=FALSE}
knitr::opts_chunk$set(message = FALSE)
```

# Introduction

The main intent of this notebook is to demonstrate starter code for predictive crop and cropping systems distribution mapping and the associated statistical small area estimates [SAE](https://www.census.gov/srd/csrm/SmallArea.html), which define the crop and cropping systems types in a given region of interest ([ROI](https://en.wikipedia.org/wiki/Region_of_interest)). We use both Rwanda's most recent and some of its legacy cropland survey (label) data here and the associated gridded raster (features) to illustrate the general approach and the main data analysis steps. Rwanda, being a small country, is convenient for this illustration because the script will run fast so as to not test your patience in running it. The notebook is publicly maintained on [Github](https://github.com/mgwalsh/RwaSIS/blob/master/RW_priority_crops.Rmd), and you can fork and modify it from there as you see fit. You may also want to take a look at the [GeoSurvey cropland area notebook](https://osf.io/shkxp/), which describes some of the spatial prediction methods and the associated SAE estimation procedures in more detail.

# General data setup

To actually run this notebook, you will need to load the packages indicated in the chunk directly below. This allows you to assemble Rwanda-wide observations, link those to the spatial data and then model them using machine learning. 

```{r}
# Package names
packages <- c("downloader", "rgdal", "sp", "raster", "leaflet", "DT", "htmlwidgets", "devtools", "caret", "caretEnsemble", "mgcv", "MASS", "glmnet", "randomForest", "xgboost", "nnet", "plyr", "dplyr", "doParallel", "dismo", "arm")

# Install packages
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
    install.packages(packages[!installed_packages])
}

# Load packages
invisible(lapply(packages, library, character.only = TRUE))
```

## Data downloads

The following chunk downloads the data that are needed for running this particular example. Specifically, it assembles georeferenced field observations of priority crops that have been requested by [RAB](http://rab.gov.rw/index.php?id=180), including Maize, Wheat, Rice, Potato, Cassava and Bean and links these to raster and GIS data features. Note that this chunk is Mac or Linux specific and so the directory structures should be changed to run on Windows machines.

```{r}
# Create a data folder in  your current working directory
dir.create("Priority_crops", showWarnings=F)
setwd("./Priority_crops")
dir.create("Results", showWarnings=F)

# Download crop data
download("https://osf.io/zqh9y/?raw=1", "priority_crops.csv.zip", mode = "wb")
unzip("priority_crops.csv.zip", overwrite = T)
crop <- read.table("priority_crops.csv", header = T, sep = ",")

# Download GADM-L5 shapefile (courtesy of: http://www.gadm.org)
download("https://www.dropbox.com/s/fhusrzswk599crn/RWA_level5.zip?raw=1", "RWA_level5.zip", mode = "wb")
unzip("RWA_level5.zip", overwrite = T)
shape <- shapefile("gadm36_RWA_5.shp")

# Download raster stacks
download("https://osf.io/hp6v7?raw=1", "RW_250m_2020.zip", mode = "wb")
unzip("RW_250m_2020.zip", overwrite = T)
download("https://osf.io/u73pd?raw=1", "RW_GS_preds.zip", mode = "wb")
unzip("RW_GS_preds.zip", overwrite = T)
glist <- list.files(pattern="tif", full.names = T)
grids <- stack(glist)

# Download cropland mask
download("https://osf.io/bmysp/", "RW_CP_mask.zip", mode = "wb")
exdir <- "./Mask" 
unzip("RW_CP_mask.zip", exdir = exdir, overwrite = T)
```

## Priority crop occurrence data

RAB's 6 priority crop occurrence data (presence/absence) for Rwanda were assembled from 4 georeferenced surveys:

1. The currently ongoing RwaSIS survey designated as `base` (see and download the raw data at: [Kobo](https://kobo.humanitarianresponse.info/#/forms/a3jwzkBTtDvdaZJgR6YjAe/summary)). There are currently 1,290 observations in this survey. Note that this number will change during 2021/22 as the RwaSIS crop and soil surveys progress, and we will update the numbers accordingly. Also note that to the best of our knowledge these are the only crop distribution and soil data that are being collected using a spatially balanced sampling frame (see the notebook about this at: [Cropland sample notebook](https://osf.io/wn3my)). 

2. The [CIALCA Farm Heterogeneity Survey of Rwanda, (2018)](https://cialca.shinyapps.io/cialca_base_2files/) survey desinated as `s1`. There are 3,199 georeferenced observations covering Rwanda in this survey. Note that the spatial coordinates for this survey are slightly offset to the GPS locations of the surveyed households rather than to the actual locations of fields.

3. The [CNLS](https://cropnuts.com/) soil survey of Rwanda's croplands, designated as `s2`, which is openly accessible at: [OSF](https://osf.io/shvpd/). There are 597 observations in this survey where at least one of the priority crops was present. We extracted these from the crop type descriptions of the soil survey's meta-data.

4. The [RAB](http://rab.gov.rw/index.php?id=180) soil survey of lowland rice areas of Rwanda, designated as `s3`. There are 916 observations in this survey for sites where only rice was present, by design. Note that this is an [oversample](https://en.wikipedia.org/wiki/Oversampling_and_undersampling_in_data_analysis) of the rice growing area of Rwanda and should be treated as such for the purpose of the SAE analyses presented below. It is however very useful for mapping similar areas accross Rwanda, which is why it is included here. 

## Gridded data

The pre-processed Rwanda grid data (in the `grids` raster stack) were derived and reprojected from their primary open sources. You can also download the entire stack directly at [RwaSIS grids](https://osf.io/hp6v7/). The short descriptions of the included rasters, and their sources are provided in the table immediately below.

\
```{r, echo=FALSE, results='asis'}
download("https://osf.io/e2x4s?raw=1", "./Priority_crops/Grid variables.csv", mode = "wb")
vars <- read.table("./Priority_crops/Grid variables.csv", header = T, sep = ",")
datatable(vars)
```
\
These Rwanda-wide (actually Africa-wide) features will change over time and we will update them if and when needed. Also note that these are grouped by factor variables that designate the occurrence of a given crop as a [Jenny-type](https://soilandhealth.org/wp-content/uploads/01aglibrary/010159.Jenny.pdf) function *f* (*crop*) ~ (*a, c, o, r, s*) where:

* a - anthropic variables
* c - climatic variables
* o - organismal and successional variables
* r - relief / topographical variables
* s - parent material and soil related variables

The main notion is that the occurrence and distribution of croplands and crop types must always be associated with the distribution of humans and their built infrastructure, but also constrained or facilitated by changes in typically much slower environmental factors such as climate, [ecological succession](https://en.wikipedia.org/wiki/Ecological_succession), topography, parent materials and soils. Note that all of these change and interact over space-time and should be, but are currently not adequately monitored across Africa (and many other parts of the world).

## Combined Rwanda crop occurrence survey dataframe

This next chunk reprojects the crop data to the [Lambert Azimuthal Equal Area (LAEA)](https://en.wikipedia.org/wiki/Lambert_azimuthal_equal-area_projection) grid of the AfSIS raster variables and then writes out the combined dataframe `RW_priority_crop_dist.csv` into your `./Priority_crops/Results` directory, if you'd like to process those outputs in software other than R. It also generates a location map of where in Rwanda those 6k+ crop survey observations were obtained.

```{r}
# Attach GADM-L5 administrative unit names from shape
coordinates(crop) <- ~lon+lat
projection(crop) <- projection(shape)
gadm <- crop %over% shape
crop <- as.data.frame(crop)
crop <- cbind(gadm[ ,c(4,6,8,10,12)], crop)
colnames(crop) <- c("region","district","sector","cell", "village","survey","scode","lon","lat","maize","wheat","rice","potato","cassava","bean")

# Project GeoSurvey coords to grid CRS
crop.proj <- as.data.frame(project(cbind(crop$lon, crop$lat), "+proj=laea +ellps=WGS84 +lon_0=20 +lat_0=5 +units=m +no_defs"))
colnames(crop.proj) <- c("x","y")
crop <- cbind(crop, crop.proj)
coordinates(crop) <- ~x+y
projection(crop) <- projection(grids)

# Extract gridded variables at GeoSurvey locations
cropgrid <- extract(grids, crop)
gsdat <- as.data.frame(cbind(crop, cropgrid))
gsdat <- gsdat[complete.cases(gsdat[ ,c(17:72)]),] ## removes incomplete cases

# Define unique grid ID's (GID)
res.pixel <- 10000 ## specifies GID scale (res.pixel, in m) ... you can change this
xgid <- ceiling(abs(gsdat$x)/res.pixel)
ygid <- ceiling(abs(gsdat$y)/res.pixel)
gidx <- ifelse(gsdat$x<0, paste("W", xgid, sep=""), paste("E", xgid, sep=""))
gidy <- ifelse(gsdat$y<0, paste("S", ygid, sep=""), paste("N", ygid, sep=""))
GID <- paste(gidx, gidy, sep="")
gsdat <- cbind(GID, gsdat)

# Randomize and writeout dataframe
set.seed(1235813)
gsdat <- gsdat[sample(1:nrow(gsdat)), ]
write.csv(gsdat, "./Priority_crops/Results/RW_priority_crop_dist.csv", row.names = F)

# Plot combined crop survey locations
w <- leaflet() %>%
  setView(lng = mean(gsdat$lon), lat = mean(gsdat$lat), zoom = 8) %>%
  addProviderTiles(providers$OpenStreetMap.Mapnik) %>%
  addCircleMarkers(gsdat$lon, gsdat$lat, clusterOptions = markerClusterOptions())
w ## plot widget 
```
\

Note that the defined `GID` variable in the chunk above is sort of like a military style 10 Ã— 10 km grid ID that will usually contain several survey locations. You can use as waypoint input to a GPS (see e.g: [GPSBabel](https://www.gpsbabel.org)), tablet or smart phone for in-the-field navigation. We will also use it further on in the script for SAE as an alternative to using the administrative units. 

# Ensemble machine learning based mapping with `caret` and `caretEnsemble`

The following chunks calibrate crop presence/absence distribution observations using different machine learning algorithms (MLAs) to various spatial feature inputs using the [caret](https://topepo.github.io/caret/) and [caretEnsemble](https://cran.r-project.org/web/packages/caretEnsemble/index.html) packages. The main idea is to train several potentially competing algorithms with [k-fold cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)). At the end of the model training processes, the various models are ensembled (combined or stacked) on an *independent validation dataset*. To start the fitting processes covered in this section, the next chunk scrubs some of the extraneous objects in memory, sets-up labels and features, and creates a randomized (80:20%) partition between the training and validation dataframes.

```{r}
# Remove extraneous objects
rm(list=setdiff(ls(), c("gsdat","grids","glist"))) ## scrub extraneous objects in memory

# Set calibration/validation set randomization seed
seed <- 12358
set.seed(seed)

# Split data into calibration and validation sets
gsIndex <- createDataPartition(gsdat$bean, p = 4/5, list = F, times = 1)
gs_cal <- gsdat[ gsIndex,]
gs_val <- gsdat[-gsIndex,]

# GeoSurvey calibration labels
labs <- c("bean") ## insert other presence/absence labels here (e.g. maize, wheat, rice, potato or cassava)
lcal <- as.vector(t(gs_cal[labs]))
lcal <- ifelse(lcal == 1, "Y", "N")

# Raster calibration features
fcal <- gs_cal[ ,17:41,45:72]
```

Note that while we are using the `bean` distribution data here, you can also substitute the other crops as labels and specify those with the `labs` variable in the chunk above. The 5 additional crop labels are included in the `crop` dataframe, but we shall leave those for you to explore. Presented next are some starter models, which we consider to be *contrasting* both in terms of the gridded calibration features that are used, as well as the MLAs that are used in fitting the observational data to those.

## Spatial trend model with `caret`

This is a simple spatially smoothed *generalized additive model* applying the `gam` function on the `bean` observations at different sampling locations in Rwanda, based only on their distance to the fixed LAEA datum georeference. It is similar to [kriging](https://en.wikipedia.org/wiki/Kriging) with cross-validation, but is simpler and much faster to compute in this context. We use the standard `caret` syntax here to illustrate the general specification, output and prediction steps. Also note that we always save the current models as [`.Rds`](https://riptutorial.com/r/example/3650/rds-and-rdata--rda--files) files. This allows us to load the models at a later stage to e.g., re-run various analyses and/or to integrate previously fitted models into new scripts and notebooks.

```{r}
# Select spatial covariates
gf_cpv <- gs_cal[ ,42:44] ## specifies features as DX, DY & DXY coordinate rasters

# Start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc) ## this parallizes

# Control setup for cross-validation
set.seed(seed)
tc <- trainControl(method = "cv", classProbs = T, 
                   summaryFunction = twoClassSummary, allowParallel = T)

# Model training
gm <- train(gf_cpv, lcal, 
            method = "gam",
            preProc = c("center","scale"), 
            family = "binomial",
            metric = "ROC",
            trControl = tc)

# Model outputs & predictions
gm.pred <- predict(grids, gm, type = "prob") ## spatial predictions
stopCluster(mc)
fname <- paste("./Priority_crops/Results/", labs, "_gm.rds", sep = "")
saveRDS(gm, fname)
```

## Central place theory model with `caret`

Central places (*sensu* [Central place theory](https://en.wikipedia.org/wiki/Central_place_theory)) are influential variables for predicting of where specific crops are likely to occur (or not, e.g. in forest reserves or national parks). The model below focuses on central place variables such as distances to major and minor roads, urban & rural settlements, parks & reserves, cell towers & electricity networks among other largely anthropically controlled / infrastructure variables. 

```{r, results='hide'}
# Select central place covariates
gf_cpv <- gs_cal[ ,28:41] ## these are the anthropic "distance-to" central place features

# Start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# Control setup for cross validation
set.seed(seed)
tc <- trainControl(method = "cv", classProbs = T,
                   summaryFunction = twoClassSummary, allowParallel = T)

# Model training
cp <- train(gf_cpv, lcal, 
            method = "glmStepAIC",
            family = "binomial",
            preProc = c("center","scale"), 
            trControl = tc,
            metric ="ROC")

# Model outputs & predictions
cp.pred <- predict(grids, cp, type = "prob") ## central place predictions
stopCluster(mc)
fname <- paste("./Priority_crops/Results/", labs, "_cp.rds", sep = "")
saveRDS(cp, fname)
```

## Fitting several additional models with `caretEnsemble`

The next chunk fits 4 additional ML models that use the that use all of gridded calibration data with 10-fold cross-validation. You can use `caretEnsemble` instead of `caret` as long as the feature variables (`grids` in this case), and the `trainControl` methods are the same for each model in the `caretList` function. This shortens the script-length of this notebook but does not otherwise affect the overall `caret` functionality. Note however that the calculations take a bit of time to run on a normal 8-core, 16 Gb memory computer. This is not a big problem for a ROI like Rwanda, but it might be computationally challenging for larger countries like Tanzania or Ethiopia. We fit these models with 10-fold cross-validation and default-tuning of the relevant [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)).

```{r, warning = FALSE, results='hide'}
# Start doParallel to parallelize model fitting
set.seed(seed)
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# Specify model training controls
tc <- trainControl(method = "cv", number = 10, classProbs = T,
                   summaryFunction = twoClassSummary, allowParallel = TRUE, savePredictions="final")

# Fit 4 calibration models using all of the gridded features
clist <- caretList(fcal, lcal,
                   trControl = tc,
                   tuneList = NULL,
                   methodList = c("glmStepAIC", "rf", "xgbTree", "nnet"),
                   preProcess = c("center","scale"),
                   metric = "ROC")

# Generate spatial predictions
gl.pred <- predict(grids, clist$glmStepAIC, type = "prob")
rf.pred <- predict(grids, clist$rf, type = "prob")
xt.pred <- predict(grids, clist$xgbTree, type = "prob")
nn.pred <- predict(grids, clist$nnet, type = "prob")
stopCluster(mc)
fname <- paste("./Priority_crops/Results/", labs, "_clist.rds", sep = "")
saveRDS(clist, fname)
```

# Model stacking with `caret`

This next chunk fits a model ensemble with the `glmStepAIC` function from the `MASS` library using the *validation dataframe* (`gs_val`). You could explore other [meta-model](https://machinelearningmastery.com/meta-learning-in-machine-learning/) options here, but I think that this approach provides a reasonable combination and weighting of the 6 models that were produced in the previous training steps. Again, the fitting is done with cross-validation.

```{r, results = 'hide'}
# Stacking setup
preds <- stack(1-gm.pred, 1-cp.pred, 1-gl.pred, 1-rf.pred, 1-xt.pred, 1-nn.pred)
names(preds) <- c("gm","cp","gl","rf","xt","nn")

# Extract predictions on the validation set
coordinates(gs_val) <- ~x+y
projection(gs_val) <- projection(preds)
gspred <- extract(preds, gs_val) ## extracts the probabilities of each model in the stack
gspred <- as.data.frame(cbind(gs_val, gspred))

# Set validation labels and features
gs_val <- as.data.frame(gs_val)
lval <- as.vector(t(gs_val[labs])) ##  subset validation labels
lval <- ifelse(lval == 1, "Y", "N")
fval <- gspred[ ,73:78] ## subset validation features

# Start doParallel to parallelize model fitting
mc <- makeCluster(detectCores())
registerDoParallel(mc)

# Control setup
set.seed(1385321)
tc <- trainControl(method = "repeatedcv", number = 10, repeats = 3, classProbs = T, 
                   summaryFunction = twoClassSummary, allowParallel = T)

# Model training
st <- train(fval, lval,
            method = "glmStepAIC",
            family = "binomial",
            metric = "ROC",
            trControl = tc)

# Model outputs & predictions
st.pred <- predict(preds, st, type = "prob") ## stacked spatial predictions
stopCluster(mc)
fname <- paste("./Priority_crops/Results/", labs, "_st.rds", sep = "")
saveRDS(st, fname)
```

```{r, echo = FALSE}
summary(st)
```

The next chunk sets writes out the 7 prediction grids to a geotif file, which can be imported to a GIS of your choice. It also generates an overview map of the cropland occurrence probabilities for `beans` in this particular example.

```{r}
# Write prediction grids
gspreds <- stack(preds, 1-st.pred)
names(gspreds) <- c("gm","cp","gl","rf","xt","nn","st")
fname <- paste("./Priority_crops/Results/","RW_", labs, "_preds_2020.tif", sep = "")
writeRaster(gspreds, filename=fname, datatype="FLT4S", options="INTERLEAVE=BAND", overwrite=T)

# Write output data frame
coordinates(gsdat) <- ~x+y
projection(gsdat) <- projection(grids)
gspre <- extract(gspreds, gsdat)
gsout <- as.data.frame(cbind(gsdat, gspre))
fname <- paste("./Priority_crops/Results/","RW_", labs, "_out.csv", sep = "")
write.csv(gsout, fname, row.names = F)

# Apply cropland mask
cpmask <- raster("./Priority_crops/Mask/RW_CP_mask.tif")
stm.pred <- mask(1-st.pred, cpmask, inverse=FALSE, maskvalue=NA, updatevalue=NA)

# Project stm.pred to EPSG:3857
stll <- projectRaster(stm.pred, crs="+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")

# Set color pallette
pal <- colorBin("Reds", domain = 0:1, na.color = "transparent")

# Render map
w <- leaflet() %>% 
  setView(lng = mean(gsdat$lon), lat = mean(gsdat$lat), zoom = 8) %>%
  addProviderTiles(providers$OpenStreetMap.Mapnik) %>%
  addRasterImage(stll, colors = pal, opacity = 0.5) %>%
  addLegend(pal = pal, values = values(stll), title = "Probability")
w ## plot widget
```

# Small area estimates (SAE)

The term *small area* conventionally refers to small administrative areas such as e.g., *regions, districts, sectors, cells and/or villages* ... in the Rwandan context. It may also refer to any other *small domain* (e.g., `GID` or similar) within a given larger ROI. If, for example, a ground survey has been carried out for a whole a country, the sample size within any particular smaller sub-area may be too small to generate precise area estimates from the data, and *vice versa*. To deal with this problem, [SAE](https://en.wikipedia.org/wiki/Small_area_estimation) uses additional auxiliary variables, which should have much denser spatial coverage than e.g., a typical country-wide ground survey. This section of the notebook illustrates some of the possible approaches to this common estimation problem. The next chunk initially calculates small area estimates using some [random intercept models](https://www.bristol.ac.uk/cmm/learning/videos/random-intercepts.html) that include random effects for *district* and *sector in district* level administrative units. They can also estimate fixed effects such as the individual suvey data that were used to derive the estimates and more importantly those which record the actual crop distribution predictions.

```{r}
# Small area hierarchical random-effect estimates by 399 sectors in 30 districts
m0 <- glmer(bean ~ 1 + (1|district/sector), family = binomial, gsout) ## change dependent variable to maize, cassava ... here 
m1 <- glmer(bean ~ scode + (1|district/sector), family = binomial, gsout)
m2 <- glmer(bean ~ st + (1|district/sector), family = binomial, gsout)
```

```{r}
summary(m2)
```

The use of of administrative units is somewhat problematic for small area monitoring, as administrative units tend to change over time. Imagine that at some point in future that you would want to assess how crop distributions or soil condition have changed in different parts of the country, but the actual survey areas have been redistricted/renamed for some other purpose (e.g., for population growth accounting, migration and/or voting and politics). 

We therefore recommend using static, equal area units such as the 10 Ã— 10 km grid IDs (`GID`), which are ubiquitous. Note that there are other options in this context. This will avoid confusion for including both new survey data and/or for change detection, monitoring, and local policy planning. It also provides straight-forward solutions for field survey team navigation and various area-based data analyses.

# Takeaways



